# ğŸŒŒ DreamScape AI â€” From Blueprint to Prototype  
### Deliverable 2 Â· Implementation and Early Evaluation  
**Author:** Deepika Sarala Pratapa  |  **Course:** EEE 6778 â€“ Applied Machine Learning II (University of Florida)

---

## ğŸª„ Project Overview
**DreamScape AI** is a multimodal AI system that transforms written or spoken dream descriptions into **visual moodboards, ambient soundscapes, and symbolic motif graphs**.  
It bridges creativity, psychology, and machine learning â€” allowing subconscious patterns to be visualized through AI.

Deliverable 2 presents the **first fully functional prototype**, integrating:
> DreamBank dataset â†’ NLP embedding â†’ Diffusion & Audio Generation â†’ Gradio Interface (inside Jupyter)

---

## ğŸ¯ Objectives (Deliverable 2)
- Build an **end-to-end dream generation pipeline** from text ingestion to multimodal outputs.  
- Use **Sentence-BERT embeddings** and **K-Means clustering** to uncover latent dream motifs.  
- Generate images and music using **Stable Diffusion Turbo** and **MusicGen**.  
- Implement **speech transcription** (Faster-Whisper) and **motif visualization** (NER + NetworkX).  
- Embed a **Gradio-based user interface** directly within the notebook.  
- Document early evaluation metrics and visuals.

---

## ğŸ§± Repository Structure
```
dreamscape-ai/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚        â””â”€â”€ dreambank_clean.json       # Cleaned dream dataset (~1000 entries)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ setup.ipynb                     # Dataset load + schema verification
â”‚   â”œâ”€â”€ exploratory_data_analysis.ipynb # Dream length + emotion analysis
â”‚   â”œâ”€â”€ nlp_motif_extraction.ipynb      # Sentence-BERT embeddings + K-Means
â”‚   â””â”€â”€ multimodal_generation.ipynb     # Diffusion + MusicGen + Gradio UI
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ dream_length_distribution.png
â”‚   â”œâ”€â”€ eda_emotion_distribution.png
â”‚   â”œâ”€â”€ nlp_clusters.png
â”‚   â”œâ”€â”€ dream_20251109_142615.png
â”‚   â”œâ”€â”€ dream_20251109_142714_moodboard.png
â”‚   â””â”€â”€ dream_20251109_142714_motifs.png
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ ui_screenshot.png
â”‚   â””â”€â”€ deliverable2_ieee.pdf           # IEEE-format report for submission
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```
---

## ğŸ§  Dataset Summary
**Dataset:** [DreamBank Annotated â€“ Gustave Cortal (2023)](https://huggingface.co/datasets/gustavecortal/DreamBank-annotated)  
**Type:** 27,952 dream narratives with HVdC-coded emotions and characters  
**Subset Used:** 1,000 entries for experimentation  

### Preprocessing (in `setup.ipynb`)
- Dropped null or <50-character entries  
- Normalized text fields (`report â†’ text`)  
- Parsed HVdC emotion and character codes  
- Computed dream length, word counts, and descriptive statistics  
- Saved cleaned dataset as `data/processed/dreambank_clean.json`

---

## âš™ï¸ Environment Setup
### 1ï¸âƒ£ Create Environment
```bash
conda create -n dreamscape python=3.11 -y
conda activate dreamscape
pip install -r requirements.txt
```

2ï¸âƒ£ (Optional) Add Jupyter Kernel
```bash
pip install jupyterlab ipykernel
python -m ipykernel install --user --name dreamscape --display-name "DreamScape AI"
```

## â–¶ï¸ Running the Pipeline

### **Step 1 Â· Data Setup**
**Notebook:** `notebooks/setup.ipynb`  

âœ… Loads dataset from Hugging Face  
âœ… Cleans and validates schema  
âœ… Saves cleaned JSON file â†’ `data/processed/dreambank_clean.json`  

---

### **Step 2 Â· Exploratory Data Analysis**
**Notebook:** `notebooks/exploratory_data_analysis.ipynb`  

**Outputs:**
- `results/dream_length_distribution.png` â€” distribution of dream lengths  
- `results/eda_emotion_distribution.png` â€” bar plot of HVdC emotion codes  

**Observations:**
- Dreams average **171 words**, with most ranging between **50â€“250 words**.  
- Emotion tags (e.g., *AP, HA, AN, SD*) show **balanced polarity**, making the dataset suitable for affective modeling.

---

### **Step 3 Â· Motif and Embedding Extraction**
**Notebook:** `notebooks/nlp_motif_extraction.ipynb`  

âœ… Generates **Sentence-BERT embeddings (384-D)**  
âœ… Performs **K-Means clustering (k = 8)**  
âœ… Extracts **top TF-IDF keywords** per motif cluster  
âœ… Saves visualization â†’ `results/nlp_clusters.png`  

**Observations:**
- Clusters correspond to interpretable dream motifs such as **movement**, **family**, **water**, and **anxiety**.
- 
### **Step 4 Â· Multimodal Generation**

**Notebook:** `notebooks/multimodal_generation.ipynb`  

This notebook unifies **text-to-image**, **text-to-audio**, and **entity graph** modules into a single multimodal framework.

**Models Used:**

| **Component** | **Model** | **Description** |
|:---------------|:----------|:----------------|
| ğŸ–¼ï¸ **Image** | `stabilityai/sd-turbo` | Fast diffusion model for dream-like visuals |
| ğŸµ **Audio** | `facebook/musicgen-small` | Text-to-music model generating ambient soundscapes |
| ğŸ™ï¸ **ASR** | `faster-whisper (small/int8)` | Speech-to-text transcription model |
| ğŸ•¸ï¸ **Motif Graph** | `dslim/bert-base-NER` | Entity extraction for co-occurrence graph visualization |

**Outputs:**
- `results/dream_20251109_142615.png` â€” generated surreal image  
- `results/dream_20251109_142714_moodboard.png` â€” artistic collage (6 visual styles)  
- `results/dream_20251109_142714_motifs.png` â€” motif graph showing co-occurring symbols  

---

### **Step 5 Â· Interactive Gradio Interface (Inside Notebook)**

The final cell in `multimodal_generation.ipynb` launches an **interactive Gradio interface** directly within the notebook for real-time exploration.

**Features:**
- Accepts **text or audio** input  
- Toggles for *Generate Moodboard*, *Generate Motif Graph*, and *Fast Mode*  
- Displays generated **image**, **audio**, **moodboard**, **motif graph**, **toxicity score**, and **transcribed text**  
- Runs entirely **locally** on CPU or MPS â€” no cloud API required  

![Interface Screenshot](docs/ui_screenshot.png)

---

## ğŸ“Š **Early Evaluation**

| **Component** | **Avg CPU Runtime (s)** | **Notes** |
|:---------------|:----------------------:|:-----------|
| Stable Diffusion Turbo (512Â², 4 steps) | 6.3 Â± 0.7 | Fast and consistent rendering |
| Moodboard (6 tiles) | 18.6 Â± 1.8 | Multi-style batch generation |
| MusicGen Audio (8 s) | 7.9 Â± 0.8 | Smooth, ambient synthesis |
| Faster-Whisper ASR | 3.2 Â± 0.3 | Accurate and low-latency transcription |
| Motif Graph (NER) | 1.1 Â± 0.2 | Lightweight entity co-occurrence mapping |

**Example Prompt:**
> â€œMy reflection in the mirror started breathing, then turned into a bird flying through a burning city.â€

**Generated Results:**
- ğŸ–¼ï¸ **Image:** `dream_20251109_142615.png` â€“ surreal cinematic composition  
- ğŸµ **Audio:** reflective, tense ambient pads  
- ğŸ•¸ï¸ **Motif Graph:** `dream_20251109_142714_motifs.png` â€“ connections: *mirror â†’ bird â†’ city â†’ fire*  

â¡ï¸ These demonstrate strong **cross-modal semantic coherence** between text, image, and sound outputs.

---

## ğŸ§© **System Architecture**

![System Architecture](docs/architecture.png)

| **Stage** | **Description** | **Libraries / Models** |
|:-----------|:----------------|:------------------------|
| **Data Processing** | Cleaning, preprocessing, and exploratory analysis | pandas, seaborn |
| **Embedding & Clustering** | Sentence-BERT embeddings + K-Means clustering | sentence-transformers, scikit-learn |
| **Image Generation** | Text â†’ Image diffusion synthesis | diffusers (`sd-turbo`) |
| **Audio Generation** | Text â†’ Music generation | transformers (`facebook/musicgen-small`) |
| **Speech Recognition** | Audio â†’ Text transcription | faster-whisper |
| **Motif Graphing** | Named entity extraction + co-occurrence visualization | networkx, dslim/bert-base-NER |
| **Interface** | Interactive notebook-based app | Gradio |

---

## âš–ï¸ **Responsible AI Reflection**

DreamScape AI adheres to transparent, ethical, and sustainable AI practices:

- ğŸ§© **Dataset Integrity:** DreamBank (CC BY 4.0) is publicly available and anonymized.  
- ğŸ›¡ï¸ **Safety:** Detoxify filters toxic inputs; the diffusion modelâ€™s safety checker blurs sensitive content.  
- ğŸ” **Transparency:** All generated outputs are clearly labeled as AI-created.  
- ğŸ”’ **Privacy:** No personal data or prompts are stored or transmitted externally.  
- âš™ï¸ **Efficiency:** Optimized for CPU/MPS execution to minimize computational overhead.  

---

## ğŸ“š **References**

- Hall & Van de Castle (1966). *The Content Analysis of Dreams.*  
- Cortal, G. (2023). *DreamBank Annotated* [Dataset]. Hugging Face.  
- Rombach et al. (2022). *High-Resolution Image Synthesis with Latent Diffusion Models.*  
- Copet et al. (2023). *MusicGen: Simple and Controllable Music Generation.*  
- Sanh et al. (2020). *dslim/bert-base-NER.* Hugging Face.  
- Kim (2023). *Faster-Whisper.* GitHub.  
- Unitary AI (2020). *Detoxify: Toxic Comment Classification.*

---

ğŸ§¾ License

All original code Â© 2025 Deepika Sarala Pratapa â€” released under the MIT License.
DreamBank Annotated dataset Â© Gustave Cortal (2023) â€” CC BY 4.0.
---

## ğŸ‘©â€ğŸ’» **Author**

**Deepika Sarala Pratapa**  
M.S. in Applied Data Science @ University of Florida  
ğŸ“§ [dpratapa@ufl.edu](mailto:dpratapa@ufl.edu)  

---

> â€œDreamScape AI doesnâ€™t just analyze dreams â€” it brings them to life.â€ ğŸŒ 

















